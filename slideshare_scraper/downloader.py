#!/usr/bin/env python3
"""
SlideShare ç°¡å ±ä¸‹è¼‰å™¨

æ ¹æ“š CSV æª”æ¡ˆä¸­çš„ URL é€£çµï¼Œä¸‹è¼‰æ¯å€‹ç°¡å ±çš„æ‰€æœ‰æŠ•å½±ç‰‡åœ–ç‰‡ã€‚
"""

import os
import re
import csv
import time
import requests
import random
from urllib.parse import urlparse, urljoin
from typing import List, Dict, Optional
import logging
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from PIL import Image
import io

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.edge.service import Service as EdgeService
from selenium.webdriver.edge.options import Options as EdgeOptions
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.microsoft import EdgeChromiumDriverManager

from config import get_environment_config
from .constants import OUTPUT_BASE_DIR


class SlideShareDownloader:
    """SlideShare ç°¡å ±åœ–ç‰‡ä¸‹è¼‰å™¨"""

    def __init__(self, headless: bool = True, download_delay: float = 1.0,
                 max_retries: int = 3, parallel_workers: int = 1,
                 environment: str = "development"):
        """
        åˆå§‹åŒ–ä¸‹è¼‰å™¨

        Args:
            headless: æ˜¯å¦ä½¿ç”¨ç„¡é ­æ¨¡å¼
            download_delay: ä¸‹è¼‰é–“éš”æ™‚é–“ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
            parallel_workers: ä¸¦è¡Œå·¥ä½œåŸ·è¡Œç·’æ•¸é‡ï¼ˆé è¨­ï¼š1ï¼‰
            environment: ç’°å¢ƒè¨­å®š
        """
        self.config = get_environment_config(environment)
        self.headless = headless
        self.download_delay = download_delay
        self.max_retries = max_retries
        self.parallel_workers = parallel_workers
        
        # WebDriver ç›¸é—œ
        self.driver = None
        self.wait = None
        
        # çµ±è¨ˆè³‡è¨Š
        self.stats = {
            "total_presentations": 0,
            "successful_downloads": 0,
            "failed_downloads": 0,
            "total_slides": 0,
            "start_time": None,
            "end_time": None
        }
        
        # è¨­å®šæ—¥èªŒ
        self._setup_logging()
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        self.output_base = "output_files"
        self._ensure_directory_exists(self.output_base)

    def _setup_logging(self):
        """è¨­å®šæ—¥èªŒç³»çµ±"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('slideshare_downloader.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def _ensure_directory_exists(self, directory: str):
        """ç¢ºä¿ç›®éŒ„å­˜åœ¨"""
        Path(directory).mkdir(parents=True, exist_ok=True)

    def setup_driver(self):
        """è¨­å®š WebDriver"""
        try:
            chrome_options = Options()
            
            if self.headless:
                chrome_options.add_argument("--headless")
            
            # åŸºæœ¬é¸é …
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--window-size=1920,1080")
            chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
            
            # å»ºç«‹ WebDriver
            try:
                service = Service(ChromeDriverManager().install())
                self.driver = webdriver.Chrome(service=service, options=chrome_options)
            except WebDriverException as e:
                if "cannot find Chrome binary" in str(e):
                    self.logger.info("Chrome ä¸å¯ç”¨ï¼Œå˜—è©¦ä½¿ç”¨ Edge...")
                    edge_options = EdgeOptions()
                    if self.headless:
                        edge_options.add_argument("--headless")
                    edge_options.add_argument("--no-sandbox")
                    edge_options.add_argument("--disable-dev-shm-usage")
                    
                    edge_service = EdgeService(EdgeChromiumDriverManager().install())
                    self.driver = webdriver.Edge(service=edge_service, options=edge_options)
                else:
                    raise e
            
            # è¨­å®šè¶…æ™‚æ™‚é–“
            self.driver.set_page_load_timeout(60)
            self.wait = WebDriverWait(self.driver, 30)
            
            self.logger.info("WebDriver è¨­å®šå®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"è¨­å®š WebDriver æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise

    def _sanitize_filename(self, filename: str) -> str:
        """æ¸…ç†æª”æ¡ˆåç¨±ï¼Œç§»é™¤ä¸åˆæ³•å­—ç¬¦"""
        if not filename:
            return "unknown"

        # ç§»é™¤æˆ–æ›¿æ›ä¸åˆæ³•å­—ç¬¦ï¼ˆåŒ…æ‹¬å–®å¼•è™Ÿå’Œå…¶ä»–ç‰¹æ®Šå­—ç¬¦ï¼‰
        filename = re.sub(r'[<>:"/\\|?*\'`]', '_', filename)

        # ç§»é™¤å¤šé¤˜ç©ºç™½å’Œç‰¹æ®Šå­—ç¬¦
        filename = re.sub(r'\s+', ' ', filename).strip()
        filename = re.sub(r'[._\-\s]+$', '', filename)  # ç§»é™¤çµå°¾çš„é»ã€åº•ç·šã€ç ´æŠ˜è™Ÿã€ç©ºç™½
        filename = re.sub(r'^[._\-\s]+', '', filename)  # ç§»é™¤é–‹é ­çš„é»ã€åº•ç·šã€ç ´æŠ˜è™Ÿã€ç©ºç™½

        # é™åˆ¶é•·åº¦ï¼ˆè€ƒæ…® Windows è·¯å¾‘é™åˆ¶ï¼Œæ›´ä¿å®ˆçš„é•·åº¦ï¼‰
        max_length = 40  # æ¸›å°‘åˆ°40å­—ç¬¦ï¼Œç‚ºå®Œæ•´è·¯å¾‘ç•™å‡ºæ›´å¤šç©ºé–“
        if len(filename) > max_length:
            # æ™ºæ…§æˆªæ–·ï¼šå˜—è©¦åœ¨å–®è©é‚Šç•Œæˆªæ–·
            words = filename.split()
            truncated = ""
            for word in words:
                if len(truncated + " " + word) <= max_length:
                    truncated = (truncated + " " + word).strip()
                else:
                    break

            if truncated:
                filename = truncated
            else:
                # å¦‚æœå–®å€‹å–®è©å°±è¶…é•·ï¼Œç›´æ¥æˆªæ–·
                filename = filename[:max_length]

        # ç¢ºä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²
        if not filename:
            filename = "unknown"

        return filename

    def _extract_title_from_url(self, url: str) -> str:
        """å¾ URL ä¸­æå–æ¨™é¡Œ"""
        try:
            # SlideShare URL æ ¼å¼é€šå¸¸æ˜¯ /username/title-slug
            path = urlparse(url).path
            parts = path.strip('/').split('/')
            if len(parts) >= 2:
                title_slug = parts[-1]
                # å°‡ slug è½‰æ›ç‚ºå¯è®€æ¨™é¡Œ
                title = title_slug.replace('-', ' ').title()
                return self._sanitize_filename(title)
        except Exception as e:
            self.logger.warning(f"ç„¡æ³•å¾ URL æå–æ¨™é¡Œ: {e}")
        
        # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ URL çš„æœ€å¾Œéƒ¨åˆ†
        return self._sanitize_filename(url.split('/')[-1] or "unknown_presentation")

    def _get_presentation_title(self, url: str) -> str:
        """ç²å–ç°¡å ±æ¨™é¡Œ"""
        try:
            self.driver.get(url)
            time.sleep(3)
            
            # å˜—è©¦å¤šç¨®æ¨™é¡Œé¸æ“‡å™¨
            title_selectors = [
                'h1[data-cy="presentation-title"]',
                'h1.slideshow-title',
                'h1',
                '.presentation-title',
                '[data-testid="presentation-title"]'
            ]
            
            for selector in title_selectors:
                try:
                    title_element = self.driver.find_element(By.CSS_SELECTOR, selector)
                    title = title_element.text.strip()
                    if title:
                        return self._sanitize_filename(title)
                except NoSuchElementException:
                    continue
            
            # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œå¾ URL æå–
            return self._extract_title_from_url(url)
            
        except Exception as e:
            self.logger.warning(f"ç²å–æ¨™é¡Œå¤±æ•—ï¼Œä½¿ç”¨ URL æå–: {e}")
            return self._extract_title_from_url(url)

    def _extract_slide_images(self, url: str) -> List[Dict[str, str]]:
        """æå–ç°¡å ±ä¸­çš„æ‰€æœ‰æŠ•å½±ç‰‡åœ–ç‰‡"""
        try:
            self.driver.get(url)
            time.sleep(5)  # ç­‰å¾…é é¢è¼‰å…¥
            
            # ç­‰å¾…æŠ•å½±ç‰‡å®¹å™¨è¼‰å…¥
            try:
                self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.vertical-slide-image')))
            except TimeoutException:
                self.logger.warning("æŠ•å½±ç‰‡å®¹å™¨è¼‰å…¥è¶…æ™‚")
                return []
            
            # æå–æ‰€æœ‰æŠ•å½±ç‰‡åœ–ç‰‡
            slide_images = []
            img_elements = self.driver.find_elements(By.CSS_SELECTOR, '.vertical-slide-image')
            
            self.logger.info(f"æ‰¾åˆ° {len(img_elements)} å¼µæŠ•å½±ç‰‡")
            
            for i, img_element in enumerate(img_elements, 1):
                try:
                    # ç²å–æœ€é«˜è§£æåº¦çš„åœ–ç‰‡ URL
                    img_url = self._get_best_quality_image_url(img_element)
                    if img_url:
                        slide_images.append({
                            "slide_number": i,
                            "image_url": img_url,
                            "alt_text": img_element.get_attribute("alt") or f"Slide {i}"
                        })
                except Exception as e:
                    self.logger.warning(f"æå–ç¬¬ {i} å¼µæŠ•å½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
            
            return slide_images
            
        except Exception as e:
            self.logger.error(f"æå–æŠ•å½±ç‰‡åœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []

    def _get_best_quality_image_url(self, img_element) -> Optional[str]:
        """ç²å–æœ€ä½³å“è³ªçš„åœ–ç‰‡ URL"""
        try:
            # å˜—è©¦å¾ srcset ç²å–æœ€é«˜è§£æåº¦åœ–ç‰‡
            srcset = img_element.get_attribute("srcset")
            if srcset:
                # è§£æ srcsetï¼Œé¸æ“‡æœ€å¤§å°ºå¯¸
                sources = []
                for source in srcset.split(','):
                    parts = source.strip().split()
                    if len(parts) >= 2:
                        url = parts[0]
                        width_str = parts[1]
                        if width_str.endswith('w'):
                            try:
                                width = int(width_str[:-1])
                                sources.append((url, width))
                            except ValueError:
                                continue
                
                if sources:
                    # é¸æ“‡æœ€å¤§å¯¬åº¦çš„åœ–ç‰‡
                    best_source = max(sources, key=lambda x: x[1])
                    return best_source[0]
            
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ src å±¬æ€§
            return img_element.get_attribute("src")
            
        except Exception as e:
            self.logger.warning(f"ç²å–åœ–ç‰‡ URL æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None

    def _download_image(self, image_url: str, save_path: str) -> bool:
        """ä¸‹è¼‰å–®å¼µåœ–ç‰‡ä¸¦è½‰æ›ç‚º JPEG æ ¼å¼"""
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        try:
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
        except Exception as e:
            self.logger.error(f"å‰µå»ºç›®éŒ„å¤±æ•—: {e}")
            return False

        # æª¢æŸ¥è·¯å¾‘é•·åº¦
        if len(save_path) > 250:
            self.logger.warning(f"æª”æ¡ˆè·¯å¾‘éé•·ï¼Œå¯èƒ½å°è‡´ä¸‹è¼‰å¤±æ•—: {save_path}")

        for attempt in range(self.max_retries):
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Referer': 'https://www.slideshare.net/'
                }

                response = requests.get(image_url, headers=headers, timeout=30)
                response.raise_for_status()

                # æª¢æ¸¬åœ–ç‰‡æ ¼å¼ä¸¦è½‰æ›ç‚º JPEG
                try:
                    # ä½¿ç”¨ PIL é–‹å•Ÿåœ–ç‰‡
                    image = Image.open(io.BytesIO(response.content))

                    # å¦‚æœæ˜¯ RGBA æ¨¡å¼ï¼ˆæœ‰é€æ˜åº¦ï¼‰ï¼Œè½‰æ›ç‚º RGB
                    if image.mode in ('RGBA', 'LA', 'P'):
                        # å‰µå»ºç™½è‰²èƒŒæ™¯
                        background = Image.new('RGB', image.size, (255, 255, 255))
                        if image.mode == 'P':
                            image = image.convert('RGBA')
                        background.paste(image, mask=image.split()[-1] if image.mode == 'RGBA' else None)
                        image = background
                    elif image.mode != 'RGB':
                        image = image.convert('RGB')

                    # ç¢ºä¿æª”æ¡ˆå‰¯æª”åæ˜¯ .jpg
                    if not save_path.lower().endswith('.jpg'):
                        save_path = save_path.rsplit('.', 1)[0] + '.jpg'

                    # å„²å­˜ç‚ºé«˜å“è³ª JPEG
                    image.save(save_path, 'JPEG', quality=95, optimize=True)

                    self.logger.debug(f"æˆåŠŸä¸‹è¼‰ä¸¦è½‰æ›åœ–ç‰‡: {save_path}")
                    return True

                except Exception as img_error:
                    # å¦‚æœ PIL è™•ç†å¤±æ•—ï¼Œå˜—è©¦ç›´æ¥å„²å­˜åŸå§‹æª”æ¡ˆ
                    self.logger.warning(f"åœ–ç‰‡è½‰æ›å¤±æ•—ï¼Œå˜—è©¦ç›´æ¥å„²å­˜: {img_error}")

                    # æ ¹æ“šå…§å®¹é¡å‹æ±ºå®šå‰¯æª”å
                    content_type = response.headers.get('content-type', '').lower()
                    if 'webp' in content_type:
                        save_path = save_path.rsplit('.', 1)[0] + '.webp'
                    elif 'png' in content_type:
                        save_path = save_path.rsplit('.', 1)[0] + '.png'

                    with open(save_path, 'wb') as f:
                        f.write(response.content)

                    self.logger.debug(f"æˆåŠŸä¸‹è¼‰åŸå§‹æ ¼å¼åœ–ç‰‡: {save_path}")
                    return True

            except (OSError, IOError) as e:
                # æª”æ¡ˆç³»çµ±éŒ¯èª¤ï¼Œé€šå¸¸æ˜¯è·¯å¾‘å•é¡Œ
                if "No such file or directory" in str(e) or "cannot find the path" in str(e):
                    self.logger.error(f"æª”æ¡ˆè·¯å¾‘éŒ¯èª¤: {save_path}")
                    self.logger.error(f"éŒ¯èª¤è©³æƒ…: {e}")
                    return False
                else:
                    self.logger.warning(f"æª”æ¡ˆç³»çµ±éŒ¯èª¤ (å˜—è©¦ {attempt + 1}/{self.max_retries}): {e}")
            except Exception as e:
                self.logger.warning(f"ä¸‹è¼‰åœ–ç‰‡å¤±æ•— (å˜—è©¦ {attempt + 1}/{self.max_retries}): {e}")

            if attempt < self.max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•¸é€€é¿

        return False

    def _download_presentation(self, url: str, title: str, output_dir: str, csv_index: Optional[int] = None) -> Dict:
        """ä¸‹è¼‰å–®å€‹ç°¡å ±çš„æ‰€æœ‰æŠ•å½±ç‰‡"""
        result = {
            "url": url,
            "title": title,
            "success": False,
            "slides_downloaded": 0,
            "total_slides": 0,
            "error": None,
            "output_path": None
        }

        try:
            self.logger.info(f"é–‹å§‹ä¸‹è¼‰ç°¡å ±: {title}")

            # ç²å–ç°¡å ±æ¨™é¡Œï¼ˆå¦‚æœæ²’æœ‰æä¾›ï¼‰
            if not title or title == "unknown":
                title = self._get_presentation_title(url)

            # å‰µå»ºç°¡å ±å°ˆç”¨ç›®éŒ„ï¼Œç¢ºä¿è·¯å¾‘ä¸æœƒéé•·
            sanitized_title = self._sanitize_filename(title)

            # å¦‚æœæœ‰ CSV ç·¨è™Ÿï¼Œæ·»åŠ ç·¨è™Ÿå‰ç¶´
            if csv_index is not None:
                dir_name = f"{csv_index:03d}_{sanitized_title}"
            else:
                dir_name = sanitized_title

            presentation_dir = os.path.join(output_dir, dir_name)

            # æª¢æŸ¥å®Œæ•´è·¯å¾‘é•·åº¦ï¼ˆWindows é™åˆ¶ç´„ 260 å­—ç¬¦ï¼‰
            if len(presentation_dir) > 200:  # ä¿å®ˆä¼°è¨ˆï¼Œç•™å‡ºç©ºé–“çµ¦æª”æ¡ˆå
                # é€²ä¸€æ­¥ç¸®çŸ­ç›®éŒ„å
                short_title = sanitized_title[:20] + "_" + str(hash(title) % 10000)
                if csv_index is not None:
                    short_dir_name = f"{csv_index:03d}_{short_title}"
                else:
                    short_dir_name = short_title
                presentation_dir = os.path.join(output_dir, short_dir_name)
                self.logger.warning(f"è·¯å¾‘éé•·ï¼Œç¸®çŸ­ç›®éŒ„åï¼š{dir_name} -> {short_dir_name}")

            self._ensure_directory_exists(presentation_dir)
            result["output_path"] = presentation_dir

            # æå–æ‰€æœ‰æŠ•å½±ç‰‡åœ–ç‰‡
            slide_images = self._extract_slide_images(url)
            result["total_slides"] = len(slide_images)

            if not slide_images:
                result["error"] = "æœªæ‰¾åˆ°æŠ•å½±ç‰‡åœ–ç‰‡"
                return result

            # ä¸‹è¼‰æ¯å¼µæŠ•å½±ç‰‡
            successful_downloads = 0
            for slide_info in slide_images:
                slide_num = slide_info["slide_number"]
                image_url = slide_info["image_url"]

                # ç”Ÿæˆæª”æ¡ˆåç¨±ï¼šæ¨™é¡Œ_ç·¨è™Ÿ.jpgï¼Œç¢ºä¿æª”æ¡ˆåä¸æœƒéé•·
                base_filename = self._sanitize_filename(title)
                # é€²ä¸€æ­¥é™åˆ¶æª”æ¡ˆåé•·åº¦ï¼Œç‚ºç·¨è™Ÿå’Œå‰¯æª”åç•™å‡ºç©ºé–“
                if len(base_filename) > 30:
                    base_filename = base_filename[:30]
                filename = f"{base_filename}_{slide_num:03d}.jpg"
                save_path = os.path.join(presentation_dir, filename)

                # æœ€çµ‚æª¢æŸ¥å®Œæ•´è·¯å¾‘é•·åº¦
                if len(save_path) > 250:  # Windows è·¯å¾‘é™åˆ¶
                    # ä½¿ç”¨æ›´çŸ­çš„æª”æ¡ˆå
                    short_filename = f"slide_{slide_num:03d}.jpg"
                    save_path = os.path.join(presentation_dir, short_filename)
                    self.logger.debug(f"è·¯å¾‘éé•·ï¼Œä½¿ç”¨ç°¡åŒ–æª”æ¡ˆåï¼š{short_filename}")

                # å¦‚æœæª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³é
                if os.path.exists(save_path):
                    self.logger.debug(f"æª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³é: {filename}")
                    successful_downloads += 1
                    continue

                # ä¸‹è¼‰åœ–ç‰‡
                if self._download_image(image_url, save_path):
                    successful_downloads += 1
                    self.stats["total_slides"] += 1

                # ä¸‹è¼‰é–“éš”
                time.sleep(self.download_delay)

            result["slides_downloaded"] = successful_downloads
            result["success"] = successful_downloads > 0

            if result["success"]:
                self.logger.info(f"ç°¡å ±ä¸‹è¼‰å®Œæˆ: {title} ({successful_downloads}/{len(slide_images)} å¼µ)")
            else:
                result["error"] = "æ‰€æœ‰æŠ•å½±ç‰‡ä¸‹è¼‰å¤±æ•—"

        except Exception as e:
            result["error"] = str(e)
            self.logger.error(f"ä¸‹è¼‰ç°¡å ±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        return result

    def download_from_csv_file(self, csv_file_path: str, output_dir: Optional[str] = None) -> Dict:
        """å¾ CSV æª”æ¡ˆä¸‹è¼‰ç°¡å ±ï¼ˆæ”¯æ´ä¸¦è¡Œè™•ç†ï¼‰"""
        if output_dir is None:
            output_dir = self.output_base

        self._ensure_directory_exists(output_dir)

        results = {
            "csv_file": csv_file_path,
            "output_directory": output_dir,
            "presentations": [],
            "summary": {
                "total_presentations": 0,
                "successful_downloads": 0,
                "failed_downloads": 0,
                "total_slides": 0
            }
        }

        try:
            # è®€å– CSV æª”æ¡ˆ
            with open(csv_file_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                presentations = list(reader)

            if not presentations:
                self.logger.warning(f"CSV æª”æ¡ˆç‚ºç©º: {csv_file_path}")
                return results

            self.logger.info(f"å¾ {csv_file_path} è®€å–åˆ° {len(presentations)} å€‹ç°¡å ±")
            self.logger.info(f"ä½¿ç”¨ {self.parallel_workers} å€‹ä¸¦è¡Œå·¥ä½œåŸ·è¡Œç·’")
            results["summary"]["total_presentations"] = len(presentations)

            if self.parallel_workers == 1:
                # å–®åŸ·è¡Œç·’æ¨¡å¼ï¼ˆåŸæœ‰é‚è¼¯ï¼‰
                self.setup_driver()

                for i, presentation in enumerate(presentations, 1):
                    url = presentation.get("é€£çµ", "").strip()
                    title = presentation.get("æ¨™é¡Œ", "").strip()

                    if not url:
                        self.logger.warning(f"ç¬¬ {i} ç­†è³‡æ–™ç¼ºå°‘ URLï¼Œè·³é")
                        continue

                    self.logger.info(f"è™•ç†ç¬¬ {i}/{len(presentations)} å€‹ç°¡å ±: {title}")

                    download_result = self._download_presentation(url, title, output_dir, csv_index=i)
                    results["presentations"].append(download_result)

                    if download_result["success"]:
                        results["summary"]["successful_downloads"] += 1
                        results["summary"]["total_slides"] += download_result["slides_downloaded"]
                    else:
                        results["summary"]["failed_downloads"] += 1

                    self.logger.info(f"é€²åº¦: {i}/{len(presentations)} å®Œæˆ")

                if self.driver:
                    self.driver.quit()
                    self.logger.info("WebDriver å·²é—œé–‰")

            else:
                # å¤šåŸ·è¡Œç·’ä¸¦è¡Œæ¨¡å¼
                tasks = []
                for i, presentation in enumerate(presentations, 1):
                    url = presentation.get("é€£çµ", "").strip()
                    title = presentation.get("æ¨™é¡Œ", "").strip()

                    if not url:
                        self.logger.warning(f"ç¬¬ {i} ç­†è³‡æ–™ç¼ºå°‘ URLï¼Œè·³é")
                        continue

                    tasks.append({
                        "task_id": i,
                        "url": url,
                        "title": title,
                        "output_dir": output_dir,
                        "worker_id": None  # å°‡åœ¨åŸ·è¡Œæ™‚åˆ†é…
                    })

                # åŸ·è¡Œä¸¦è¡Œä¸‹è¼‰
                start_time = time.time()
                with ThreadPoolExecutor(max_workers=self.parallel_workers) as executor:
                    # ç‚ºæ¯å€‹ä»»å‹™åˆ†é…å·¥ä½œåŸ·è¡Œç·’ ID
                    for i, task in enumerate(tasks):
                        task["worker_id"] = (i % self.parallel_workers) + 1

                    # æäº¤æ‰€æœ‰ä»»å‹™
                    future_to_task = {
                        executor.submit(self._download_presentation_worker, task): task
                        for task in tasks
                    }

                    # æ”¶é›†çµæœ
                    completed = 0
                    for future in as_completed(future_to_task):
                        try:
                            download_result = future.result()
                            results["presentations"].append(download_result)

                            if download_result["success"]:
                                results["summary"]["successful_downloads"] += 1
                                results["summary"]["total_slides"] += download_result["slides_downloaded"]
                            else:
                                results["summary"]["failed_downloads"] += 1

                            completed += 1
                            elapsed_time = time.time() - start_time
                            self.logger.info(f"é€²åº¦: {completed}/{len(tasks)} å®Œæˆ | è€—æ™‚: {elapsed_time:.1f}s")

                        except Exception as e:
                            task = future_to_task[future]
                            self.logger.error(f"ä»»å‹™ {task['task_id']} åŸ·è¡Œå¤±æ•—: {e}")
                            results["presentations"].append({
                                "task_id": task["task_id"],
                                "url": task["url"],
                                "title": task["title"],
                                "success": False,
                                "error": f"åŸ·è¡Œç·’ç•°å¸¸: {e}",
                                "slides_downloaded": 0,
                                "total_slides": 0
                            })
                            results["summary"]["failed_downloads"] += 1

        except Exception as e:
            self.logger.error(f"è™•ç† CSV æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            results["error"] = str(e)

        return results

    def _download_presentation_worker(self, task_info: Dict) -> Dict:
        """
        ä¸¦è¡Œå·¥ä½œåŸ·è¡Œç·’ï¼šä¸‹è¼‰å–®å€‹ç°¡å ±

        Args:
            task_info: åŒ…å«ä»»å‹™è³‡è¨Šçš„å­—å…¸

        Returns:
            ä¸‹è¼‰çµæœå­—å…¸
        """
        url = task_info["url"]
        title = task_info["title"]
        output_dir = task_info["output_dir"]
        worker_id = task_info["worker_id"]
        task_id = task_info["task_id"]

        result = {
            "worker_id": worker_id,
            "task_id": task_id,
            "url": url,
            "title": title,
            "success": False,
            "slides_downloaded": 0,
            "total_slides": 0,
            "error": None,
            "output_path": None
        }

        # ç‚ºæ¯å€‹å·¥ä½œåŸ·è¡Œç·’å‰µå»ºç¨ç«‹çš„ WebDriver
        driver = None
        try:
            # æ·»åŠ å•Ÿå‹•å»¶é²ï¼Œé¿å…åŒæ™‚å•Ÿå‹•å¤ªå¤šç€è¦½å™¨
            startup_delay = random.uniform(0, 3)
            time.sleep(startup_delay)

            self.logger.info(f"[å·¥ä½œåŸ·è¡Œç·’ {worker_id}] é–‹å§‹ä¸‹è¼‰ç°¡å ±: {title}")

            # è¨­å®šç¨ç«‹çš„ WebDriver
            chrome_options = Options()
            if self.headless:
                chrome_options.add_argument("--headless")

            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--window-size=1920,1080")
            chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")

            try:
                service = Service(ChromeDriverManager().install())
                driver = webdriver.Chrome(service=service, options=chrome_options)
            except WebDriverException as e:
                if "cannot find Chrome binary" in str(e):
                    edge_options = EdgeOptions()
                    if self.headless:
                        edge_options.add_argument("--headless")
                    edge_options.add_argument("--no-sandbox")
                    edge_options.add_argument("--disable-dev-shm-usage")

                    edge_service = EdgeService(EdgeChromiumDriverManager().install())
                    driver = webdriver.Edge(service=edge_service, options=edge_options)
                else:
                    raise e

            driver.set_page_load_timeout(60)
            wait = WebDriverWait(driver, 30)

            # ç²å–ç°¡å ±æ¨™é¡Œï¼ˆå¦‚æœæ²’æœ‰æä¾›ï¼‰
            if not title or title == "unknown":
                driver.get(url)
                time.sleep(3)

                title_selectors = [
                    'h1[data-cy="presentation-title"]',
                    'h1.slideshow-title',
                    'h1',
                    '.presentation-title',
                    '[data-testid="presentation-title"]'
                ]

                for selector in title_selectors:
                    try:
                        title_element = driver.find_element(By.CSS_SELECTOR, selector)
                        title = title_element.text.strip()
                        if title:
                            title = self._sanitize_filename(title)
                            break
                    except NoSuchElementException:
                        continue

                if not title:
                    title = self._extract_title_from_url(url)

            # å‰µå»ºç°¡å ±å°ˆç”¨ç›®éŒ„ï¼Œç¢ºä¿è·¯å¾‘ä¸æœƒéé•·
            sanitized_title = self._sanitize_filename(title)

            # æ·»åŠ  CSV ç·¨è™Ÿå‰ç¶´
            dir_name = f"{task_id:03d}_{sanitized_title}"
            presentation_dir = os.path.join(output_dir, dir_name)

            # æª¢æŸ¥å®Œæ•´è·¯å¾‘é•·åº¦
            if len(presentation_dir) > 200:
                short_title = sanitized_title[:20] + "_" + str(hash(title) % 10000)
                short_dir_name = f"{task_id:03d}_{short_title}"
                presentation_dir = os.path.join(output_dir, short_dir_name)
                self.logger.warning(f"[å·¥ä½œåŸ·è¡Œç·’ {worker_id}] è·¯å¾‘éé•·ï¼Œç¸®çŸ­ç›®éŒ„åï¼š{dir_name} -> {short_dir_name}")

            self._ensure_directory_exists(presentation_dir)
            result["output_path"] = presentation_dir

            # æå–æ‰€æœ‰æŠ•å½±ç‰‡åœ–ç‰‡
            driver.get(url)
            time.sleep(5)

            try:
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.vertical-slide-image')))
            except TimeoutException:
                result["error"] = "æŠ•å½±ç‰‡å®¹å™¨è¼‰å…¥è¶…æ™‚"
                return result

            img_elements = driver.find_elements(By.CSS_SELECTOR, '.vertical-slide-image')
            result["total_slides"] = len(img_elements)

            if not img_elements:
                result["error"] = "æœªæ‰¾åˆ°æŠ•å½±ç‰‡åœ–ç‰‡"
                return result

            self.logger.info(f"[å·¥ä½œåŸ·è¡Œç·’ {worker_id}] æ‰¾åˆ° {len(img_elements)} å¼µæŠ•å½±ç‰‡")

            # ä¸‹è¼‰æ¯å¼µæŠ•å½±ç‰‡
            successful_downloads = 0
            for i, img_element in enumerate(img_elements, 1):
                try:
                    img_url = self._get_best_quality_image_url(img_element)
                    if img_url:
                        # ç”Ÿæˆæª”æ¡ˆåç¨±ï¼Œç¢ºä¿ä¸æœƒéé•·
                        base_filename = self._sanitize_filename(title)
                        if len(base_filename) > 30:
                            base_filename = base_filename[:30]
                        filename = f"{base_filename}_{i:03d}.jpg"
                        save_path = os.path.join(presentation_dir, filename)

                        # æª¢æŸ¥å®Œæ•´è·¯å¾‘é•·åº¦
                        if len(save_path) > 250:
                            short_filename = f"slide_{i:03d}.jpg"
                            save_path = os.path.join(presentation_dir, short_filename)

                        if os.path.exists(save_path):
                            successful_downloads += 1
                            continue

                        if self._download_image(img_url, save_path):
                            successful_downloads += 1

                        time.sleep(self.download_delay)

                except Exception as e:
                    self.logger.warning(f"[å·¥ä½œåŸ·è¡Œç·’ {worker_id}] æå–ç¬¬ {i} å¼µæŠ•å½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue

            result["slides_downloaded"] = successful_downloads
            result["success"] = successful_downloads > 0

            if result["success"]:
                self.logger.info(f"[å·¥ä½œåŸ·è¡Œç·’ {worker_id}] ç°¡å ±ä¸‹è¼‰å®Œæˆ: {title} ({successful_downloads}/{len(img_elements)} å¼µ)")
            else:
                result["error"] = "æ‰€æœ‰æŠ•å½±ç‰‡ä¸‹è¼‰å¤±æ•—"

        except Exception as e:
            result["error"] = str(e)
            self.logger.error(f"[å·¥ä½œåŸ·è¡Œç·’ {worker_id}] ä¸‹è¼‰ç°¡å ±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        finally:
            if driver:
                driver.quit()

        return result

    def download_from_directory(self, input_directory: str, output_dir: Optional[str] = None,
                               file_pattern: str = "*.csv", category_filter: Optional[str] = None,
                               section_filter: Optional[str] = None) -> Dict:
        """å¾ç›®éŒ„ä¸­çš„æ‰€æœ‰ CSV æª”æ¡ˆä¸‹è¼‰ç°¡å ±"""
        if output_dir is None:
            output_dir = self.output_base

        self._ensure_directory_exists(output_dir)

        # æ‰¾åˆ°æ‰€æœ‰ CSV æª”æ¡ˆ
        input_path = Path(input_directory)
        all_csv_files = list(input_path.glob(file_pattern))

        # æ‡‰ç”¨éæ¿¾å™¨
        csv_files = []
        for csv_file in all_csv_files:
            filename = csv_file.stem

            # æ‡‰ç”¨é¡åˆ¥éæ¿¾å™¨
            if category_filter and category_filter.lower() not in filename.lower():
                continue
            # æ‡‰ç”¨å€å¡Šéæ¿¾å™¨
            if section_filter and section_filter.lower() not in filename.lower():
                continue

            csv_files.append(csv_file)

        if not csv_files:
            if category_filter or section_filter:
                self.logger.warning(f"åœ¨ç›®éŒ„ {input_directory} ä¸­æœªæ‰¾åˆ°ç¬¦åˆéæ¿¾æ¢ä»¶çš„ CSV æª”æ¡ˆ")
                return {"error": f"æœªæ‰¾åˆ°ç¬¦åˆéæ¿¾æ¢ä»¶çš„ CSV æª”æ¡ˆï¼ˆé¡åˆ¥ï¼š{category_filter}ï¼Œå€å¡Šï¼š{section_filter}ï¼‰"}
            else:
                self.logger.warning(f"åœ¨ç›®éŒ„ {input_directory} ä¸­æœªæ‰¾åˆ° CSV æª”æ¡ˆ")
                return {"error": "æœªæ‰¾åˆ° CSV æª”æ¡ˆ"}

        self.logger.info(f"æ‰¾åˆ° {len(csv_files)} å€‹ CSV æª”æ¡ˆ")

        all_results = {
            "input_directory": input_directory,
            "output_directory": output_dir,
            "csv_files": [],
            "total_summary": {
                "total_csv_files": len(csv_files),
                "total_presentations": 0,
                "successful_downloads": 0,
                "failed_downloads": 0,
                "total_slides": 0
            }
        }

        # è™•ç†æ¯å€‹ CSV æª”æ¡ˆ
        for csv_file in csv_files:
            self.logger.info(f"è™•ç† CSV æª”æ¡ˆ: {csv_file.name}")

            # ç‚ºæ¯å€‹ CSV æª”æ¡ˆå‰µå»ºå­ç›®éŒ„
            csv_output_dir = os.path.join(output_dir, csv_file.stem)

            # ä¸‹è¼‰è©² CSV æª”æ¡ˆä¸­çš„æ‰€æœ‰ç°¡å ±
            file_results = self.download_from_csv_file(str(csv_file), csv_output_dir)
            all_results["csv_files"].append(file_results)

            # ç´¯è¨ˆçµ±è¨ˆ
            summary = file_results.get("summary", {})
            all_results["total_summary"]["total_presentations"] += summary.get("total_presentations", 0)
            all_results["total_summary"]["successful_downloads"] += summary.get("successful_downloads", 0)
            all_results["total_summary"]["failed_downloads"] += summary.get("failed_downloads", 0)
            all_results["total_summary"]["total_slides"] += summary.get("total_slides", 0)

        return all_results

    def download_from_url_directory(self, url_directory: str,
                                   category_filter: Optional[str] = None,
                                   section_filter: Optional[str] = None) -> Dict:
        """
        å¾ output_url ç›®éŒ„ä¸‹è¼‰ç°¡å ±

        Args:
            url_directory: output_url ç›®éŒ„è·¯å¾‘
            category_filter: é¡åˆ¥éæ¿¾å™¨ï¼ˆå¯é¸ï¼‰
            section_filter: å€å¡Šéæ¿¾å™¨ï¼ˆå¯é¸ï¼‰
        """
        url_path = Path(url_directory)
        if not url_path.exists():
            return {"error": f"ç›®éŒ„ä¸å­˜åœ¨: {url_directory}"}

        # æ‰¾åˆ°æ‰€æœ‰æ™‚é–“æˆ³ç›®éŒ„
        timestamp_dirs = [d for d in url_path.iterdir() if d.is_dir()]

        if not timestamp_dirs:
            return {"error": f"åœ¨ {url_directory} ä¸­æœªæ‰¾åˆ°æ™‚é–“æˆ³ç›®éŒ„"}

        # é¸æ“‡æœ€æ–°çš„ç›®éŒ„
        latest_dir = max(timestamp_dirs, key=lambda x: x.stat().st_mtime)
        self.logger.info(f"ä½¿ç”¨æœ€æ–°çš„ URL ç›®éŒ„: {latest_dir.name}")

        # æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„ CSV æª”æ¡ˆ
        csv_files = []
        for csv_file in latest_dir.glob("*.csv"):
            filename = csv_file.stem

            # æ‡‰ç”¨éæ¿¾å™¨
            if category_filter and category_filter.lower() not in filename.lower():
                continue
            if section_filter and section_filter.lower() not in filename.lower():
                continue

            csv_files.append(csv_file)

        if not csv_files:
            return {"error": "æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„ CSV æª”æ¡ˆ"}

        self.logger.info(f"æ‰¾åˆ° {len(csv_files)} å€‹ç¬¦åˆæ¢ä»¶çš„ CSV æª”æ¡ˆ")

        # å‰µå»ºå°æ‡‰çš„è¼¸å‡ºç›®éŒ„
        output_dir = os.path.join(self.output_base, latest_dir.name)

        # ä¸‹è¼‰æ‰€æœ‰ç¬¦åˆæ¢ä»¶çš„ç°¡å ±
        return self.download_from_directory(str(latest_dir), output_dir, "*.csv")

    def print_summary(self, results: Dict):
        """åˆ—å°ä¸‹è¼‰æ‘˜è¦"""
        print("\n" + "="*70)
        print("ğŸ“¥ SlideShare ç°¡å ±ä¸‹è¼‰æ‘˜è¦")
        print("="*70)

        if "total_summary" in results:
            summary = results["total_summary"]
            print(f"ğŸ“ è™•ç†çš„ CSV æª”æ¡ˆ: {summary.get('total_csv_files', 0)} å€‹")
            print(f"ğŸ“Š ç¸½ç°¡å ±æ•¸é‡: {summary.get('total_presentations', 0)} å€‹")
            print(f"âœ… æˆåŠŸä¸‹è¼‰: {summary.get('successful_downloads', 0)} å€‹")
            print(f"âŒ ä¸‹è¼‰å¤±æ•—: {summary.get('failed_downloads', 0)} å€‹")
            print(f"ğŸ–¼ï¸  ç¸½æŠ•å½±ç‰‡æ•¸: {summary.get('total_slides', 0)} å¼µ")

            if summary.get('total_presentations', 0) > 0:
                success_rate = (summary.get('successful_downloads', 0) /
                              summary.get('total_presentations', 1)) * 100
                print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")

        elif "summary" in results:
            summary = results["summary"]
            print(f"ğŸ“Š ç¸½ç°¡å ±æ•¸é‡: {summary.get('total_presentations', 0)} å€‹")
            print(f"âœ… æˆåŠŸä¸‹è¼‰: {summary.get('successful_downloads', 0)} å€‹")
            print(f"âŒ ä¸‹è¼‰å¤±æ•—: {summary.get('failed_downloads', 0)} å€‹")
            print(f"ğŸ–¼ï¸  ç¸½æŠ•å½±ç‰‡æ•¸: {summary.get('total_slides', 0)} å¼µ")

        if "output_directory" in results:
            print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {results['output_directory']}")

        print("="*70)
